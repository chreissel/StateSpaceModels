{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76fde93d-a59c-491b-96d8-fe4c2b5f12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import numpy as np\n",
    "from data.gen_signal import build_empty_signal, gauss_sig\n",
    "from data.gen_noise_spectrum import generate_time_from_psd, f2\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2484c-4193-499c-8224-0330fe90e576",
   "metadata": {},
   "source": [
    "# Generate dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02a68c33-3eb3-4fde-85ae-bb7b09fe5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(size = 10000, std_min = 10, std_max = 30, amp_min = 1, amp_max = 10, num_pulses = 1, std_length = 3):\n",
    "\n",
    "    sr = 2**5\n",
    "\n",
    "    # generate psd first, assuming some binning(anything)\n",
    "    largest_frequency = 1000\n",
    "    num_bins = 700\n",
    "    freqs = np.linspace(0, largest_frequency, num_bins)\n",
    "    \n",
    "    # generate spikes of noise\n",
    "    num_spikes = 10\n",
    "    psd = np.zeros(num_bins)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        psd, freq_spectrum, noise_time = generate_time_from_psd(num_bins*2, sr, largest_frequency, num_bins, f2, {\"num_spikes\":10})\n",
    "\n",
    "        x, t = build_empty_signal(noise_time.shape[0], sr)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            sig = gauss_sig(x, t, std_min, std_max, amp_min, amp_max, num_pulses, std_length)\n",
    "            X.append(sig + noise_time)\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            X.append(noise_time)\n",
    "            Y.append(0)\n",
    "        \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44ff418a-44ca-43cc-8b96-2dc83724bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Toy_loader(Dataset):\n",
    "    def __init__(self, normalize=True):\n",
    "        X, y = build_toy_dataset(size = 10000, std_min = 10, std_max = 30, amp_min = 1, amp_max = 10, num_pulses = 1, std_length = 3)\n",
    "        X = X[:, :, np.newaxis] # to fit the convention of the SSM\n",
    "        self.timeseries = np.float32(X)\n",
    "        #self.labels = np.stack([np.float32(~y), np.float32(y)], axis=1)\n",
    "        #self.labels = np.int32(y)\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        times = self.timeseries[idx, :, :]\n",
    "        labels = self.labels[idx]\n",
    "        return times, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d91881-e174-4a47-978c-fc26a024addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = Toy_loader(normalize=True)\n",
    "generator = torch.Generator().manual_seed(42) \n",
    "trainset, valset, testset = torch.utils.data.random_split(fulldata, [0.7,0.1,0.2], generator=generator)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "381c8857-75f6-4602-be20-5b18d6ec2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "plt.plot(batch[0][0].numpy())\n",
    "plt.xlabel(\"time\")\n",
    "\n",
    "print((batch[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c6a60-1534-45c0-8b3d-305bd20fe699",
   "metadata": {},
   "source": [
    "# Initialize SSM (or alternative) to do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a39cc553-cd0e-4619-8708-4a61ce8a8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.s4d import S4D\n",
    "import torch.nn as nn\n",
    "\n",
    "d_input = 1\n",
    "d_output = 2\n",
    "\n",
    "dropout_fn = nn.Dropout2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b004b16-6d67-4a13-a8de-e24defafb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of SSM here\n",
    "class S4Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output=10,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, 0.01))\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c350e21c-8bd2-4b5c-80aa-583f66d7cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN counterpart\n",
    "# code adopted from here: https://github.com/ML4GW/summer-projects-2023/blob/neurips-2023/symmetry-informed-flows/notebooks/DampedHarmonicOscillator/damped-harmonic-oscillator-with-similarity-embedding-training.ipynb\n",
    "\n",
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        kernel_size=5,\n",
    "        activation=torch.nn.functional.relu,\n",
    "        dropout_probability=0.1,\n",
    "        use_batch_norm=True,\n",
    "        zero_initialization=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList(\n",
    "                [nn.BatchNorm1d(channels, eps=1e-3) for _ in range(2)]\n",
    "            )\n",
    "        self.conv_layers = nn.ModuleList(\n",
    "            [nn.Conv1d(channels, channels, kernel_size=kernel_size, padding='same') for _ in range(2)] #2 is for 2 conv layers\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        if zero_initialization:\n",
    "            nn.init.uniform_(self.conv_layers[-1].weight, -1e-3, 1e-3)\n",
    "            nn.init.uniform_(self.conv_layers[-1].bias, -1e-3, 1e-3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        temps = inputs\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.conv_layers[0](temps)\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.dropout(temps)\n",
    "        temps = self.conv_layers[1](temps)\n",
    "        return inputs + temps\n",
    "\n",
    "class ConvResidualNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        hidden_channels,\n",
    "        num_blocks=2,\n",
    "        kernel_size=5,\n",
    "        activation=torch.nn.functional.relu,\n",
    "        dropout_probability=0.1,\n",
    "        use_batch_norm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.initial_layer = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "        )\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvResidualBlock(\n",
    "                    channels=hidden_channels,\n",
    "                    activation=activation,\n",
    "                    dropout_probability=dropout_probability,\n",
    "                    use_batch_norm=use_batch_norm,\n",
    "                    kernel_size=kernel_size,\n",
    "                )\n",
    "                for _ in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "        self.final_layer = nn.Conv1d(\n",
    "            hidden_channels, out_channels, kernel_size=1, padding='same'\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.initial_layer(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_layer(x)\n",
    "        \n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ddd380f-ce78-4ef3-a69f-31f8e28f3d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "architecture = 'SSM'\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "if architecture == 'SSM':\n",
    "    model = S4Model(d_input=1, d_output=d_output, d_model=128, n_layers=4, dropout=0.0, prenorm=False)\n",
    "elif architecture == 'CNN':\n",
    "    model = ConvResidualNet(in_channels=1, out_channels=2, hidden_channels=20, num_blocks=4, kernel_size=21)\n",
    "else:\n",
    "    print('Inteded architecture not available.')\n",
    "    \n",
    "model = model.to(device)\n",
    "print('...done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f112aec2-dc78-4046-a337-e6a384c67679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer group 0 | 28 tensors | lr 0.01 | weight_decay 0.01\n",
      "Optimizer group 1 | 12 tensors | lr 0.001 | weight_decay 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "def setup_optimizer(model, lr, weight_decay, epochs):\n",
    "    \"\"\"\n",
    "    S4 requires a specific optimizer setup.\n",
    "\n",
    "    The S4 layer (A, B, C, dt) parameters typically\n",
    "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
    "\n",
    "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
    "    and weight decay (if desired).\n",
    "    \"\"\"\n",
    "\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts\n",
    "    for hp in hps:\n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp]\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    # Print optimizer info\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if architecture == 'SSM':\n",
    "    optimizer, scheduler = setup_optimizer(model, lr=0.01, weight_decay=0.01, epochs=10)\n",
    "else:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14486965-5273-4734-b410-a7bb79d025dc",
   "metadata": {},
   "source": [
    "# Actual training (standard torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f19e4474-0205-4f41-91ca-44d6ba90d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb839f3-10bb-4c5d-b0ce-12aa1a486e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 1.098 | Acc: 45.703% (234/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 1.098 | Acc: 45.703% (234/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 1.934 | Acc: 48.535% (497/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 1.934 | Acc: 48.535% (497/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 1.602 | Acc: 48.828% (750/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 1.602 | Acc: 48.828% (750/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 1.476 | Acc: 49.854% (1021/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 1.476 | Acc: 49.854% (1021/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 1.378 | Acc: 49.844% (1276/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 1.378 | Acc: 49.844% (1276/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 1.273 | Acc: 49.642% (1525/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 1.273 | Acc: 49.642% (1525/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 1.192 | Acc: 49.498% (1774/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 1.192 | Acc: 49.498% (1774/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 1.139 | Acc: 49.414% (2024/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 1.139 | Acc: 49.414% (2024/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 1.101 | Acc: 49.089% (2262/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 1.101 | Acc: 49.089% (2262/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 1.062 | Acc: 49.316% (2525/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 1.062 | Acc: 49.316% (2525/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 1.029 | Acc: 49.450% (2785/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 1.029 | Acc: 49.450% (2785/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 1.002 | Acc: 49.251% (3026/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 1.002 | Acc: 49.251% (3026/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.978 | Acc: 49.669% (3306/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.978 | Acc: 49.669% (3306/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.961 | Acc: 49.557% (3469/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.961 | Acc: 49.557% (3469/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.727 | Acc: 48.828% (250/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.727 | Acc: 48.828% (250/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.711 | Acc: 52.100% (521/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.711 | Acc: 52.100% (521/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.743 | Acc: 45.508% (233/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.743 | Acc: 45.508% (233/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.734 | Acc: 47.266% (484/1024): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.734 | Acc: 47.266% (484/1024): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.730 | Acc: 48.112% (739/1536): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.730 | Acc: 48.112% (739/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.726 | Acc: 48.900% (978/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.726 | Acc: 48.900% (978/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 1 | Val acc: 52.100:  10%|         | 1/10 [00:08<01:14,  8.26s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.709 | Acc: 52.539% (269/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.709 | Acc: 52.539% (269/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.714 | Acc: 49.707% (509/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.714 | Acc: 49.707% (509/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.708 | Acc: 49.349% (758/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.708 | Acc: 49.349% (758/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.705 | Acc: 49.072% (1005/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.705 | Acc: 49.072% (1005/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.705 | Acc: 49.141% (1258/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.705 | Acc: 49.141% (1258/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.706 | Acc: 49.382% (1517/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.706 | Acc: 49.382% (1517/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.706 | Acc: 49.358% (1769/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.706 | Acc: 49.358% (1769/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.704 | Acc: 50.122% (2053/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.704 | Acc: 50.122% (2053/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.702 | Acc: 50.477% (2326/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.702 | Acc: 50.477% (2326/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.701 | Acc: 50.371% (2579/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.701 | Acc: 50.371% (2579/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.700 | Acc: 50.994% (2872/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.700 | Acc: 50.994% (2872/5632): : 11it [00:05,  1.94it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.700 | Acc: 50.798% (3121/6144): : 11it [00:06,  1.94it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.700 | Acc: 50.798% (3121/6144): : 12it [00:06,  1.94it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.700 | Acc: 50.781% (3380/6656): : 12it [00:06,  1.94it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.700 | Acc: 50.781% (3380/6656): : 13it [00:06,  1.94it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.700 | Acc: 50.843% (3559/7000): : 13it [00:07,  1.94it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.700 | Acc: 50.843% (3559/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.703 | Acc: 48.828% (250/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.703 | Acc: 48.828% (250/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.694 | Acc: 52.100% (521/1000): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.694 | Acc: 52.100% (521/1000): : 2it [00:00,  5.06it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.712 | Acc: 45.508% (233/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.712 | Acc: 45.508% (233/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.707 | Acc: 47.266% (484/1024): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.707 | Acc: 47.266% (484/1024): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.705 | Acc: 48.112% (739/1536): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.705 | Acc: 48.112% (739/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.702 | Acc: 48.900% (978/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.702 | Acc: 48.900% (978/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 2 | Val acc: 52.100:  20%|        | 2/10 [00:16<01:05,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.694 | Acc: 52.148% (267/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.694 | Acc: 52.148% (267/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.697 | Acc: 50.098% (513/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.697 | Acc: 50.098% (513/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.695 | Acc: 49.609% (762/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.695 | Acc: 49.609% (762/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.694 | Acc: 49.463% (1013/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.694 | Acc: 49.463% (1013/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.694 | Acc: 49.492% (1267/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.694 | Acc: 49.492% (1267/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.695 | Acc: 49.154% (1510/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.695 | Acc: 49.154% (1510/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.695 | Acc: 49.358% (1769/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.695 | Acc: 49.358% (1769/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.694 | Acc: 49.927% (2045/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.694 | Acc: 49.927% (2045/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.694 | Acc: 49.978% (2303/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.694 | Acc: 49.978% (2303/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.693 | Acc: 51.855% (2655/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.693 | Acc: 51.855% (2655/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.692 | Acc: 51.847% (2920/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.692 | Acc: 51.847% (2920/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.692 | Acc: 51.595% (3170/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.692 | Acc: 51.595% (3170/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.692 | Acc: 51.578% (3433/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.692 | Acc: 51.578% (3433/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.691 | Acc: 51.443% (3601/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.691 | Acc: 51.443% (3601/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.685 | Acc: 48.828% (250/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.685 | Acc: 48.828% (250/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.681 | Acc: 52.100% (521/1000): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.681 | Acc: 52.100% (521/1000): : 2it [00:00,  5.06it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.688 | Acc: 45.508% (233/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.688 | Acc: 45.508% (233/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.686 | Acc: 47.266% (484/1024): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.686 | Acc: 47.266% (484/1024): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.685 | Acc: 48.112% (739/1536): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.685 | Acc: 48.112% (739/1536): : 3it [00:00,  4.92it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.684 | Acc: 48.900% (978/2000): : 3it [00:00,  4.92it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.684 | Acc: 48.900% (978/2000): : 4it [00:00,  5.04it/s]\u001b[A\n",
      "Epoch: 3 | Val acc: 52.100:  30%|       | 3/10 [00:24<00:57,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.683 | Acc: 49.805% (255/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.683 | Acc: 49.805% (255/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.681 | Acc: 49.609% (508/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.681 | Acc: 49.609% (508/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.680 | Acc: 57.422% (882/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.680 | Acc: 57.422% (882/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.679 | Acc: 57.422% (1176/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.679 | Acc: 57.422% (1176/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.678 | Acc: 56.562% (1448/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.678 | Acc: 56.562% (1448/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.676 | Acc: 57.389% (1763/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.676 | Acc: 57.389% (1763/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.673 | Acc: 59.598% (2136/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.673 | Acc: 59.598% (2136/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.670 | Acc: 64.380% (2637/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.670 | Acc: 64.380% (2637/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.667 | Acc: 62.218% (2867/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.667 | Acc: 62.218% (2867/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.661 | Acc: 65.742% (3366/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.661 | Acc: 65.742% (3366/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.655 | Acc: 67.685% (3812/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.655 | Acc: 67.685% (3812/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.646 | Acc: 69.613% (4277/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.646 | Acc: 69.613% (4277/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.635 | Acc: 71.214% (4740/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.635 | Acc: 71.214% (4740/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.623 | Acc: 72.114% (5048/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.623 | Acc: 72.114% (5048/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.407 | Acc: 93.359% (478/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.407 | Acc: 93.359% (478/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.410 | Acc: 91.700% (917/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.410 | Acc: 91.700% (917/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.414 | Acc: 93.750% (480/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.414 | Acc: 93.750% (480/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.408 | Acc: 93.164% (954/1024): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.408 | Acc: 93.164% (954/1024): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.408 | Acc: 92.643% (1423/1536): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.408 | Acc: 92.643% (1423/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.404 | Acc: 92.700% (1854/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.404 | Acc: 92.700% (1854/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 4 | Val acc: 91.700:  40%|      | 4/10 [00:32<00:49,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.415 | Acc: 92.383% (473/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.415 | Acc: 92.383% (473/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.377 | Acc: 93.066% (953/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.377 | Acc: 93.066% (953/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.356 | Acc: 92.057% (1414/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.356 | Acc: 92.057% (1414/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.332 | Acc: 91.650% (1877/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.332 | Acc: 91.650% (1877/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.312 | Acc: 91.562% (2344/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.312 | Acc: 91.562% (2344/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.294 | Acc: 91.862% (2822/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.294 | Acc: 91.862% (2822/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.280 | Acc: 91.853% (3292/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.280 | Acc: 91.853% (3292/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.277 | Acc: 91.260% (3738/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.277 | Acc: 91.260% (3738/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.273 | Acc: 90.907% (4189/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.273 | Acc: 90.907% (4189/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.264 | Acc: 91.074% (4663/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.264 | Acc: 91.074% (4663/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.343 | Acc: 87.571% (4932/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.343 | Acc: 87.571% (4932/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.330 | Acc: 87.923% (5402/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.330 | Acc: 87.923% (5402/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.329 | Acc: 87.665% (5835/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.329 | Acc: 87.665% (5835/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.335 | Acc: 87.400% (6118/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.335 | Acc: 87.400% (6118/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.460 | Acc: 79.492% (407/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.460 | Acc: 79.492% (407/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.510 | Acc: 77.600% (776/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.510 | Acc: 77.600% (776/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.472 | Acc: 78.906% (404/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.472 | Acc: 78.906% (404/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.456 | Acc: 79.199% (811/1024): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.456 | Acc: 79.199% (811/1024): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.467 | Acc: 78.906% (1212/1536): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.467 | Acc: 78.906% (1212/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.476 | Acc: 78.750% (1575/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.476 | Acc: 78.750% (1575/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 5 | Val acc: 77.600:  50%|     | 5/10 [00:41<00:41,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.465 | Acc: 78.906% (404/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.465 | Acc: 78.906% (404/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.511 | Acc: 77.148% (790/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.511 | Acc: 77.148% (790/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.496 | Acc: 77.865% (1196/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.496 | Acc: 77.865% (1196/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.479 | Acc: 78.467% (1607/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.479 | Acc: 78.467% (1607/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.453 | Acc: 79.531% (2036/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.453 | Acc: 79.531% (2036/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.431 | Acc: 81.120% (2492/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.431 | Acc: 81.120% (2492/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.413 | Acc: 82.729% (2965/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.413 | Acc: 82.729% (2965/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.406 | Acc: 84.399% (3457/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.406 | Acc: 84.399% (3457/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.402 | Acc: 85.807% (3954/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.402 | Acc: 85.807% (3954/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.399 | Acc: 87.012% (4455/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.399 | Acc: 87.012% (4455/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.397 | Acc: 87.908% (4951/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.397 | Acc: 87.908% (4951/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.393 | Acc: 88.656% (5447/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.393 | Acc: 88.656% (5447/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.387 | Acc: 89.288% (5943/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.387 | Acc: 89.288% (5943/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.381 | Acc: 89.514% (6266/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.381 | Acc: 89.514% (6266/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.269 | Acc: 93.555% (479/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.269 | Acc: 93.555% (479/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.275 | Acc: 92.500% (925/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.275 | Acc: 92.500% (925/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.281 | Acc: 92.383% (473/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.281 | Acc: 92.383% (473/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.270 | Acc: 93.066% (953/1024): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.270 | Acc: 93.066% (953/1024): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.271 | Acc: 92.773% (1425/1536): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.271 | Acc: 92.773% (1425/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.275 | Acc: 92.400% (1848/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.275 | Acc: 92.400% (1848/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 6 | Val acc: 92.500:  60%|    | 6/10 [00:49<00:32,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.279 | Acc: 91.602% (469/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.279 | Acc: 91.602% (469/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.263 | Acc: 91.992% (942/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.263 | Acc: 91.992% (942/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.263 | Acc: 91.667% (1408/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.263 | Acc: 91.667% (1408/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.258 | Acc: 91.504% (1874/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.258 | Acc: 91.504% (1874/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.257 | Acc: 91.289% (2337/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.257 | Acc: 91.289% (2337/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.252 | Acc: 91.504% (2811/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.252 | Acc: 91.504% (2811/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.257 | Acc: 90.820% (3255/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.257 | Acc: 90.820% (3255/3584): : 7it [00:03,  1.94it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.253 | Acc: 90.771% (3718/4096): : 7it [00:04,  1.94it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.253 | Acc: 90.771% (3718/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.247 | Acc: 91.037% (4195/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.247 | Acc: 91.037% (4195/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.244 | Acc: 91.074% (4663/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.244 | Acc: 91.074% (4663/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.240 | Acc: 91.175% (5135/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.240 | Acc: 91.175% (5135/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.234 | Acc: 91.406% (5616/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.234 | Acc: 91.406% (5616/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.230 | Acc: 91.602% (6097/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.230 | Acc: 91.602% (6097/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.225 | Acc: 91.743% (6422/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.225 | Acc: 91.743% (6422/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.148 | Acc: 96.875% (496/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.148 | Acc: 96.875% (496/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.155 | Acc: 96.400% (964/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.155 | Acc: 96.400% (964/1000): : 2it [00:00,  5.06it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.155 | Acc: 97.266% (498/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.155 | Acc: 97.266% (498/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.151 | Acc: 97.266% (996/1024): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.151 | Acc: 97.266% (996/1024): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.152 | Acc: 97.070% (1491/1536): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.152 | Acc: 97.070% (1491/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.153 | Acc: 96.750% (1935/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.153 | Acc: 96.750% (1935/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 7 | Val acc: 96.400:  70%|   | 7/10 [00:57<00:24,  8.25s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.152 | Acc: 96.484% (494/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.152 | Acc: 96.484% (494/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.151 | Acc: 96.387% (987/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.151 | Acc: 96.387% (987/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.149 | Acc: 96.875% (1488/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.149 | Acc: 96.875% (1488/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.147 | Acc: 97.266% (1992/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.147 | Acc: 97.266% (1992/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.145 | Acc: 97.539% (2497/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.145 | Acc: 97.539% (2497/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.144 | Acc: 97.689% (3001/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.144 | Acc: 97.689% (3001/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.140 | Acc: 97.963% (3511/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.140 | Acc: 97.963% (3511/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.137 | Acc: 98.022% (4015/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.137 | Acc: 98.022% (4015/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.135 | Acc: 97.895% (4511/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.135 | Acc: 97.895% (4511/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.132 | Acc: 97.930% (5014/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.132 | Acc: 97.930% (5014/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.128 | Acc: 97.940% (5516/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.128 | Acc: 97.940% (5516/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.126 | Acc: 97.900% (6015/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.126 | Acc: 97.900% (6015/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.124 | Acc: 97.867% (6514/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.124 | Acc: 97.867% (6514/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.123 | Acc: 97.714% (6840/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.123 | Acc: 97.714% (6840/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.098 | Acc: 97.070% (497/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.098 | Acc: 97.070% (497/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.108 | Acc: 96.000% (960/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.108 | Acc: 96.000% (960/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.099 | Acc: 96.484% (494/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.099 | Acc: 96.484% (494/512): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.102 | Acc: 96.582% (989/1024): : 1it [00:00,  4.95it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.102 | Acc: 96.582% (989/1024): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.103 | Acc: 96.549% (1483/1536): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.103 | Acc: 96.549% (1483/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.102 | Acc: 96.450% (1929/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.102 | Acc: 96.450% (1929/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 8 | Val acc: 96.000:  80%|  | 8/10 [01:05<00:16,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.090 | Acc: 97.852% (501/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.090 | Acc: 97.852% (501/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.095 | Acc: 97.070% (994/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.095 | Acc: 97.070% (994/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.096 | Acc: 96.940% (1489/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.096 | Acc: 96.940% (1489/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.094 | Acc: 97.070% (1988/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.094 | Acc: 97.070% (1988/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.092 | Acc: 97.383% (2493/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.092 | Acc: 97.383% (2493/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.092 | Acc: 97.266% (2988/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.092 | Acc: 97.266% (2988/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.094 | Acc: 97.154% (3482/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.094 | Acc: 97.154% (3482/3584): : 7it [00:03,  1.94it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.094 | Acc: 97.095% (3977/4096): : 7it [00:04,  1.94it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.094 | Acc: 97.095% (3977/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.092 | Acc: 97.092% (4474/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.092 | Acc: 97.092% (4474/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.092 | Acc: 97.090% (4971/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.092 | Acc: 97.090% (4971/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.092 | Acc: 97.053% (5466/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.092 | Acc: 97.053% (5466/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.091 | Acc: 97.054% (5963/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.091 | Acc: 97.054% (5963/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.092 | Acc: 96.980% (6455/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.092 | Acc: 96.980% (6455/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.092 | Acc: 96.957% (6787/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.092 | Acc: 96.957% (6787/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.093 | Acc: 96.875% (496/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.093 | Acc: 96.875% (496/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.102 | Acc: 96.000% (960/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.102 | Acc: 96.000% (960/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.092 | Acc: 96.484% (494/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.092 | Acc: 96.484% (494/512): : 1it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.095 | Acc: 96.582% (989/1024): : 1it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.095 | Acc: 96.582% (989/1024): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.096 | Acc: 96.484% (1482/1536): : 2it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.096 | Acc: 96.484% (1482/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.095 | Acc: 96.400% (1928/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.095 | Acc: 96.400% (1928/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 9 | Val acc: 96.000:  90%| | 9/10 [01:14<00:08,  8.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.087 | Acc: 97.070% (497/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/14) | Loss: 0.087 | Acc: 97.070% (497/512): : 1it [00:00,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.084 | Acc: 97.168% (995/1024): : 1it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (1/14) | Loss: 0.084 | Acc: 97.168% (995/1024): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.084 | Acc: 97.070% (1491/1536): : 2it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (2/14) | Loss: 0.084 | Acc: 97.070% (1491/1536): : 3it [00:01,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.090 | Acc: 96.631% (1979/2048): : 3it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (3/14) | Loss: 0.090 | Acc: 96.631% (1979/2048): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.089 | Acc: 96.758% (2477/2560): : 4it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (4/14) | Loss: 0.089 | Acc: 96.758% (2477/2560): : 5it [00:02,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.090 | Acc: 96.549% (2966/3072): : 5it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (5/14) | Loss: 0.090 | Acc: 96.549% (2966/3072): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.089 | Acc: 96.763% (3468/3584): : 6it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (6/14) | Loss: 0.089 | Acc: 96.763% (3468/3584): : 7it [00:03,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.090 | Acc: 96.606% (3957/4096): : 7it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (7/14) | Loss: 0.090 | Acc: 96.606% (3957/4096): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.090 | Acc: 96.701% (4456/4608): : 8it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (8/14) | Loss: 0.090 | Acc: 96.701% (4456/4608): : 9it [00:04,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.090 | Acc: 96.719% (4952/5120): : 9it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (9/14) | Loss: 0.090 | Acc: 96.719% (4952/5120): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.089 | Acc: 96.804% (5452/5632): : 10it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (10/14) | Loss: 0.089 | Acc: 96.804% (5452/5632): : 11it [00:05,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.088 | Acc: 96.908% (5954/6144): : 11it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (11/14) | Loss: 0.088 | Acc: 96.908% (5954/6144): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.088 | Acc: 96.950% (6453/6656): : 12it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (12/14) | Loss: 0.088 | Acc: 96.950% (6453/6656): : 13it [00:06,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.087 | Acc: 97.000% (6790/7000): : 13it [00:07,  1.95it/s]\u001b[A\n",
      "Batch Idx: (13/14) | Loss: 0.087 | Acc: 97.000% (6790/7000): : 14it [00:07,  1.99it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.091 | Acc: 97.461% (499/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/2) | Loss: 0.091 | Acc: 97.461% (499/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.098 | Acc: 96.600% (966/1000): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/2) | Loss: 0.098 | Acc: 96.600% (966/1000): : 2it [00:00,  5.05it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.091 | Acc: 97.070% (497/512): : 0it [00:00, ?it/s]\u001b[A\n",
      "Batch Idx: (0/4) | Loss: 0.091 | Acc: 97.070% (497/512): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.093 | Acc: 97.070% (994/1024): : 1it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (1/4) | Loss: 0.093 | Acc: 97.070% (994/1024): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.094 | Acc: 96.940% (1489/1536): : 2it [00:00,  4.94it/s]\u001b[A\n",
      "Batch Idx: (2/4) | Loss: 0.094 | Acc: 96.940% (1489/1536): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.092 | Acc: 96.900% (1938/2000): : 3it [00:00,  4.93it/s]\u001b[A\n",
      "Batch Idx: (3/4) | Loss: 0.092 | Acc: 96.900% (1938/2000): : 4it [00:00,  5.05it/s]\u001b[A\n",
      "Epoch: 9 | Val acc: 96.000: 100%|| 10/10 [01:22<00:00,  8.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(train_loader))\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "            (batch_idx, len(train_loader), train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "        )\n",
    "\n",
    "\n",
    "def eval(epoch, dataloader, checkpoint=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(dataloader))\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                (batch_idx, len(dataloader), eval_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "            )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if checkpoint:\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "        return acc\n",
    "\n",
    "pbar = tqdm(range(start_epoch, 10))\n",
    "for epoch in pbar:\n",
    "    if epoch == 0:\n",
    "        pbar.set_description('Epoch: %d' % (epoch))\n",
    "    else:\n",
    "        pbar.set_description('Epoch: %d | Val acc: %1.3f' % (epoch, val_acc))\n",
    "    train()\n",
    "    val_acc = eval(epoch, valid_loader, checkpoint=True)\n",
    "    eval(epoch, test_loader)\n",
    "    scheduler.step()\n",
    "    # print(f\"Epoch {epoch} learning rate: {scheduler.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb07f3a-4ee4-4bb7-8637-2a1425a298bb",
   "metadata": {},
   "source": [
    "# Add here some diagnostics etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a71e249e-f962-49c2-b804-ac3918cc71e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200194\n"
     ]
    }
   ],
   "source": [
    "# get number of trainable parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c564811-863d-4fba-a134-5ee8a23041d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3-ssm]",
   "language": "python",
   "name": "conda-env-miniforge3-ssm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
